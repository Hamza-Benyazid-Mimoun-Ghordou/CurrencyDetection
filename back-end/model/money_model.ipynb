{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "740fefc4",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 118s 1us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "pre_trained_model = tf.keras.applications.ResNet50(\n",
    "    include_top=False, weights=\"imagenet\",\n",
    "    input_shape=(256, 256, 3), classes=6\n",
    ")\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = True\n",
    "  \n",
    "# pre_trained_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35a16194",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = './images2/training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5525e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pre_trained_model.output\n",
    "# creating model\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = tf.keras.layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = tf.keras.layers.Dense  (6, activation='softmax')(x)           \n",
    "model = tf.keras.models.Model( pre_trained_model.input, x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce444863",
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "_______________\nconv4_block2_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block2_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block2_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block2_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_out (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n                                                                 conv4_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block3_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block3_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block3_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_out (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n                                                                 conv4_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block4_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block4_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block4_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_out (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n                                                                 conv4_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block5_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block5_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block5_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_out (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n                                                                 conv4_block5_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block5_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_preact_relu (Activ (None, 16, 16, 1024) 0           conv4_block6_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262144      conv4_block6_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_2_pad (ZeroPadding (None, 18, 18, 256)  0           conv4_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_conv (Conv2D)    (None, 8, 8, 256)    589824      conv4_block6_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block6_2_bn (BatchNormali (None, 8, 8, 256)    1024        conv4_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_relu (Activation (None, 8, 8, 256)    0           conv4_block6_2_bn[0][0]          \n__________________________________________________________________________________________________\nmax_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 1024)   0           conv4_block5_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_3_conv (Conv2D)    (None, 8, 8, 1024)   263168      conv4_block6_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_out (Add)          (None, 8, 8, 1024)   0           max_pooling2d_5[0][0]            \n                                                                 conv4_block6_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_preact_bn (BatchNo (None, 8, 8, 1024)   4096        conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block1_preact_relu (Activ (None, 8, 8, 1024)   0           conv5_block1_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524288      conv5_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block1_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_conv[0][0]        \n                                                                 conv5_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block2_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block2_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block2_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block2_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_out (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n                                                                 conv5_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_preact_bn (BatchNo (None, 8, 8, 2048)   8192        conv5_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block3_preact_relu (Activ (None, 8, 8, 2048)   0           conv5_block3_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1048576     conv5_block3_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_2_pad (ZeroPadding (None, 10, 10, 512)  0           conv5_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359296     conv5_block3_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_out (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n                                                                 conv5_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\npost_bn (BatchNormalization)    (None, 8, 8, 2048)   8192        conv5_block3_out[0][0]           \n__________________________________________________________________________________________________\npost_relu (Activation)          (None, 8, 8, 2048)   0           post_bn[0][0]                    \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 131072)       0           post_relu[0][0]                  \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 1024)         134218752   flatten_1[0][0]                  \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 6)            6150        dropout_1[0][0]                  \n==================================================================================================\nTotal params: 157,789,702\nTrainable params: 157,744,262\nNon-trainable params: 45,440\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "946b4fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StopCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc') > .98 and logs.get('val_acc') > .98):\n",
    "      print(\"objective reached, stoping training ...\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "stop_callback = StopCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f4568eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a356421",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 557 images belonging to 6 classes.\nFound 137 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range = 180,\n",
    "    width_shift_range = .2,\n",
    "    height_shift_range = .2,\n",
    "    shear_range = .6,\n",
    "    zoom_range = .6,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode = 'nearest',\n",
    "    validation_split=.2,\n",
    ")\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size = (256, 256),\n",
    "    batch_size = 10,\n",
    "    class_mode = 'categorical',\n",
    "    subset='training'\n",
    ")\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size = (256, 256),\n",
    "    batch_size = 5,\n",
    "    class_mode = 'categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ef6f8e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "111/111 - 230s - loss: 0.2589 - acc: 0.9040 - val_loss: 0.8810 - val_acc: 0.8741\n",
      "Epoch 2/20\n",
      "111/111 - 233s - loss: 0.3058 - acc: 0.8913 - val_loss: 0.2816 - val_acc: 0.9185\n",
      "Epoch 3/20\n",
      "111/111 - 232s - loss: 0.2404 - acc: 0.9112 - val_loss: 0.3936 - val_acc: 0.8593\n",
      "Epoch 4/20\n",
      "111/111 - 233s - loss: 0.2736 - acc: 0.9203 - val_loss: 0.7343 - val_acc: 0.8963\n",
      "Epoch 5/20\n",
      "111/111 - 232s - loss: 0.2717 - acc: 0.9203 - val_loss: 0.3821 - val_acc: 0.9037\n",
      "Epoch 6/20\n",
      "111/111 - 222s - loss: 0.2389 - acc: 0.9257 - val_loss: 0.4716 - val_acc: 0.8741\n",
      "Epoch 7/20\n",
      "111/111 - 211s - loss: 0.2527 - acc: 0.9130 - val_loss: 0.4555 - val_acc: 0.8963\n",
      "Epoch 8/20\n",
      "111/111 - 211s - loss: 0.2259 - acc: 0.9167 - val_loss: 0.2790 - val_acc: 0.8741\n",
      "Epoch 9/20\n",
      "111/111 - 211s - loss: 0.2837 - acc: 0.9149 - val_loss: 1.4954 - val_acc: 0.7852\n",
      "Epoch 10/20\n",
      "111/111 - 198s - loss: 0.3087 - acc: 0.9004 - val_loss: 0.5519 - val_acc: 0.8741\n",
      "Epoch 11/20\n",
      "111/111 - 198s - loss: 0.2188 - acc: 0.9297 - val_loss: 0.8268 - val_acc: 0.8296\n",
      "Epoch 12/20\n",
      "111/111 - 202s - loss: 0.2575 - acc: 0.9185 - val_loss: 0.4543 - val_acc: 0.8593\n",
      "Epoch 13/20\n",
      "111/111 - 1470s - loss: 0.2136 - acc: 0.9312 - val_loss: 0.5465 - val_acc: 0.8815\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f87d7f57a984>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m       \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3021\u001b[0m       (graph_function,\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3023\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1960\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples//train_generator.batch_size,  \n",
    "      epochs=30,\n",
    "      verbose=2,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps=validation_generator.samples//validation_generator.batch_size,\n",
    "      callbacks=[stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ecb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6aba73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}