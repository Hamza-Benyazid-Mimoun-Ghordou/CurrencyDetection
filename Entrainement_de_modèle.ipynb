{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Entrainement de mod√®le",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O2GW5Gmxoe4"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from shutil import copyfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdflU6gB0mTo"
      },
      "source": [
        "**Mount google drive that containes training data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_0WVtzFy5EK",
        "outputId": "12366d21-aada-49e4-b2d2-03eb5a273fc3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkN8SP5M4EvS",
        "outputId": "308e57b9-8d37-45e5-be0f-832aa896676f"
      },
      "source": [
        "#you should change this variable to your project directory\n",
        "project_directory = '/content/drive/Shareddrives/PFA 1A/'\n",
        "images_directory = project_directory+'/images'\n",
        "print(len(os.listdir(project_directory)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfA5RAvD02s0"
      },
      "source": [
        "**Load pre-trained model and make its layers trainable**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2usOvnEtGgKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e0a4e12-9bf0-45a4-c1fd-4ec3024173db"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "pretrained_model = ResNet50(include_top=False,weights=\"imagenet\",input_shape=(256,256,3),input_tensor=None)\n",
        "\n",
        "for layer in pretrained_model.layers :\n",
        "  layer.trainable=True\n",
        "\n",
        "# pretrained_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZaAfc7w1BE3"
      },
      "source": [
        "**Add your output layers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2gcun4-Jw5G",
        "outputId": "5d5e0104-913a-4446-ac69-017ab362ddf4"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "\n",
        "x= pretrained_model.output\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(x)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final softmax layer for classification\n",
        "x = layers.Dense  (6, activation='softmax')(x)  \n",
        "\n",
        "model = Model(pretrained_model.input,x)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(lr=0.0001),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 131072)       0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         134218752   flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 6)            6150        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 157,812,614\n",
            "Trainable params: 157,759,494\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOj3r9aR1IY-"
      },
      "source": [
        "**Create your data generator**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8PVw5-mFhi9",
        "outputId": "cbe19716-5cff-43ad-f026-c0492e71e883"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range = 180,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    shear_range = 0.5,\n",
        "    zoom_range = 0.5,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest',\n",
        "    validation_split=0.2\n",
        ")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    images_directory+'/training',\n",
        "    target_size = (256,256),\n",
        "    batch_size = 5,\n",
        "    class_mode = 'categorical',\n",
        "    subset='training'\n",
        ")\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    images_directory+'/training',\n",
        "    target_size = (256,256),\n",
        "    batch_size = 5,\n",
        "    class_mode = 'categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 446 images belonging to 6 classes.\n",
            "Found 108 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drepbqONvlQB"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "# When to save the model\n",
        "checkpointer = ModelCheckpoint(filepath=project_directory+'/model.weights.best.hdf5', verbose=0, \n",
        "                               save_best_only=True)\n",
        "\n",
        "# Reduce learning rate when loss doesn't improve after n epochs\n",
        "scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                              patience=5, min_lr=1e-8, verbose=0)\n",
        "\n",
        "# Stop early if model doesn't improve after n epochs\n",
        "early_stopper = EarlyStopping(monitor='val_loss', patience=10,\n",
        "                              verbose=0, restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g94Zui6xG26X",
        "outputId": "62a34a64-f441-4739-8625-ad8ac38ece5b"
      },
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_generator.samples//train_generator.batch_size,\n",
        "    epochs = 25,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = validation_generator.samples//validation_generator.batch_size,\n",
        "    verbose = 2,\n",
        "    callbacks=[scheduler,early_stopper]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "89/89 - 69s - loss: 1.0554 - accuracy: 0.8005 - val_loss: 14.5113 - val_accuracy: 0.0762\n",
            "Epoch 2/25\n",
            "89/89 - 66s - loss: 0.5141 - accuracy: 0.8821 - val_loss: 24.3332 - val_accuracy: 0.1524\n",
            "Epoch 3/25\n",
            "89/89 - 66s - loss: 0.6652 - accuracy: 0.8526 - val_loss: 34.7059 - val_accuracy: 0.2476\n",
            "Epoch 4/25\n",
            "89/89 - 67s - loss: 0.4367 - accuracy: 0.8912 - val_loss: 20.9533 - val_accuracy: 0.2667\n",
            "Epoch 5/25\n",
            "89/89 - 66s - loss: 0.4137 - accuracy: 0.8980 - val_loss: 33.2976 - val_accuracy: 0.2571\n",
            "Epoch 6/25\n",
            "89/89 - 66s - loss: 0.3557 - accuracy: 0.9229 - val_loss: 9.0909 - val_accuracy: 0.3429\n",
            "Epoch 7/25\n",
            "89/89 - 65s - loss: 0.2634 - accuracy: 0.9274 - val_loss: 2.4586 - val_accuracy: 0.4762\n",
            "Epoch 8/25\n",
            "89/89 - 66s - loss: 0.2389 - accuracy: 0.9388 - val_loss: 2.2615 - val_accuracy: 0.5333\n",
            "Epoch 9/25\n",
            "89/89 - 66s - loss: 0.2912 - accuracy: 0.9342 - val_loss: 1.0660 - val_accuracy: 0.7429\n",
            "Epoch 10/25\n",
            "89/89 - 66s - loss: 0.2905 - accuracy: 0.9524 - val_loss: 1.5677 - val_accuracy: 0.9048\n",
            "Epoch 11/25\n",
            "89/89 - 66s - loss: 0.1521 - accuracy: 0.9546 - val_loss: 1.1325 - val_accuracy: 0.8571\n",
            "Epoch 12/25\n",
            "89/89 - 66s - loss: 0.1095 - accuracy: 0.9705 - val_loss: 0.5683 - val_accuracy: 0.9143\n",
            "Epoch 13/25\n",
            "89/89 - 65s - loss: 0.3976 - accuracy: 0.9161 - val_loss: 2.4326 - val_accuracy: 0.9143\n",
            "Epoch 14/25\n",
            "89/89 - 66s - loss: 0.1818 - accuracy: 0.9365 - val_loss: 0.5836 - val_accuracy: 0.9143\n",
            "Epoch 15/25\n",
            "89/89 - 67s - loss: 0.2967 - accuracy: 0.9206 - val_loss: 0.2455 - val_accuracy: 0.9619\n",
            "Epoch 16/25\n",
            "89/89 - 66s - loss: 0.2935 - accuracy: 0.9229 - val_loss: 0.5704 - val_accuracy: 0.8476\n",
            "Epoch 17/25\n",
            "89/89 - 66s - loss: 0.2630 - accuracy: 0.9184 - val_loss: 1.9089 - val_accuracy: 0.9238\n",
            "Epoch 18/25\n",
            "89/89 - 66s - loss: 0.0606 - accuracy: 0.9796 - val_loss: 0.1724 - val_accuracy: 0.9429\n",
            "Epoch 19/25\n",
            "89/89 - 66s - loss: 0.1866 - accuracy: 0.9546 - val_loss: 0.1551 - val_accuracy: 0.9524\n",
            "Epoch 20/25\n",
            "89/89 - 66s - loss: 0.4160 - accuracy: 0.9184 - val_loss: 0.1127 - val_accuracy: 0.9714\n",
            "Epoch 21/25\n",
            "89/89 - 65s - loss: 0.3207 - accuracy: 0.9252 - val_loss: 0.3367 - val_accuracy: 0.9238\n",
            "Epoch 22/25\n",
            "89/89 - 65s - loss: 0.1109 - accuracy: 0.9683 - val_loss: 0.3122 - val_accuracy: 0.9238\n",
            "Epoch 23/25\n",
            "89/89 - 65s - loss: 0.1653 - accuracy: 0.9546 - val_loss: 0.9264 - val_accuracy: 0.8095\n",
            "Epoch 24/25\n",
            "89/89 - 65s - loss: 0.2077 - accuracy: 0.9433 - val_loss: 0.0725 - val_accuracy: 0.9810\n",
            "Epoch 25/25\n",
            "89/89 - 66s - loss: 0.1866 - accuracy: 0.9388 - val_loss: 0.0810 - val_accuracy: 0.9619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "aBLM7LxsLGwD",
        "outputId": "7ec5cc87-b0a3-4aa6-f2ac-65e5328c48bb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49e3tEJfzvsI"
      },
      "source": [
        "**save model so that you load it later**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqCeySBw0HlQ"
      },
      "source": [
        "**Load best weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chMUIi6pPr34",
        "outputId": "15c597e0-35b0-485f-a95a-f8c196c463e2"
      },
      "source": [
        "model.save(project_directory+'/models/model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rb9tt1FEyIL7"
      },
      "source": [
        "model.load_weights(project_directory+'/model.weights.best.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOBqH8Ty0PPF"
      },
      "source": [
        "#Test your model with images in a test folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGQttstv4SQg",
        "outputId": "90f3c1ca-f011-45f1-dc9a-be22b14b9c61"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        " \n",
        " \n",
        "# you should change this based on what input size the model trained on \n",
        "input_size = (256,256)\n",
        "\n",
        "test_images_directory = images_directory+\"/new test samples/200 dh/\" \n",
        " \n",
        "test_list = os.listdir(test_images_directory)\n",
        "\n",
        "classes = [\"10 dh\",\"100 dh\",\"20 dh\",\"200 dh\",\"5 dh\",\"50 dh\"]\n",
        "\n",
        "\n",
        " \n",
        "for fn in test_list :\n",
        " \n",
        "  # predicting images\n",
        " \n",
        "  path = test_images_directory + fn\n",
        "  \n",
        "  # copy it there\n",
        " \n",
        "  img = image.load_img(path, target_size = input_size) \n",
        "  \n",
        "  x = image.img_to_array(img)/255\n",
        "    \n",
        "  x = np.expand_dims(x, axis=0)\n",
        " \n",
        "  images = np.vstack([x])\n",
        "  \n",
        "  proba = model.predict(images, batch_size=10)\n",
        "  predict_index = proba[0].argmax()\n",
        "  max_proba = max(proba[0])\n",
        "  if max_proba < 0.9:\n",
        "    predict = \"none\"\n",
        "  else:\n",
        "    predict = classes[predict_index]\n",
        "  print(max_proba)\n",
        "  print(fn + \" is a \" + predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8816147\n",
            "16228941143082857757627906916181.jpg is a none\n",
            "0.8421239\n",
            "16228941958106279444852058058706.jpg is a none\n",
            "0.99999833\n",
            "1622894249298233023513672530293.jpg is a 200 dh\n",
            "0.9850086\n",
            "16228945104341390822418175998675.jpg is a 200 dh\n",
            "0.9998778\n",
            "16228945467832437052976403858148.jpg is a 200 dh\n",
            "0.9999596\n",
            "1622894607025539127759647648579.jpg is a 200 dh\n",
            "0.9999474\n",
            "16228946559981839704141661360800.jpg is a 200 dh\n",
            "0.99981385\n",
            "16228957698974809675407919040674.jpg is a 200 dh\n",
            "0.98712885\n",
            "16228961351511612508241591692635.jpg is a 200 dh\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}